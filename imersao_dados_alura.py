# -*- coding: utf-8 -*-
"""Imersão Dados - Alura

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a5NpcujDAI8_WVx_AMjPG5fXPAaLcxVl

**AULA 01**
"""

import pandas as pd
url = "https://gist.githubusercontent.com/tgcsantos/3bdb29eba6ce391e90df2b72205ba891/raw/22fa920e80c9fa209a9fccc8b52d74cc95d1599b/dados_imoveis.csv"
dados = pd.read_csv(url)
dados.head()

n_imoveis_bairro = dados["Bairro"].value_counts()
n_imoveis_bairro.head(10).plot.bar();

"""**AULA 02**"""

dados["Valor"].str.split(expand = True)[2].unique()

dados[["Moeda", "Valor_anuncio", "Tipo_anuncio"]] = dados["Valor"].str.split(expand = True)
dados.head()

dados[dados["Tipo_anuncio"].isnull()]["Tipo_anuncio"].unique()

dados_vendas = dados[dados["Tipo_anuncio"].isnull()]
dados_vendas

dados_vendas["Valor_anuncio"] = dados_vendas["Valor_anuncio"].str.replace(".", "").astype(float)

dados_vendas.head()

pd.set_option("display.precision", 2)
pd.set_option("display.float_format", lambda x: '%.2f' % x)
dados_vendas.describe()

"""**AULA 03**"""

dados_vendas["Valor_m2"] = dados_vendas["Valor_anuncio"]/dados_vendas["Metragem"]
dados_vendas.head()

dados_vendas.groupby("Bairro").mean()

dados_bairro = dados_vendas.groupby("Bairro").sum()
dados_bairro

dados_bairro["Valor_m2_bairro"] = dados_bairro["Valor_anuncio"]/dados_bairro["Metragem"]
dados_bairro

dados_bairro.reset_index(inplace = True)
dados_bairro

top_bairros = dados_vendas["Bairro"].value_counts()[:10].index

dados_bairro.query("Bairro in @top_bairros")

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize = (15, 10))
ax = sns.barplot(x="Bairro", y="Valor_m2_bairro", data=dados_bairro.query("Bairro in @top_bairros"), hue="Bairro")
ax.tick_params(axis='x', rotation=45)

plt.figure(figsize = (15, 10))
ax = sns.boxplot(x="Bairro", y="Valor_anuncio", data=dados_vendas.query("Bairro in @top_bairros & Valor_anuncio < 60000000"), hue="Bairro")
ax.tick_params(axis='x', rotation=45)
plt.show()

"""**Desafio aula 03**"""

ibge_url = 'https://gist.githubusercontent.com/tgcsantos/85f8c7b0a2edbc3e27fcad619b37d886/raw/a4954781e6bca9cb804062a3eea0b3b84679daf4/Basico_SP1.csv'

#indicar o separador de ; ao invés da vírgula, indicar que o decimal é com a vírgula
ibge = pd.read_csv(ibge_url, sep=';',thousands='.', decimal=',', encoding='ISO-8859-1')
ibge.head()

ibge_col = ibge.drop(columns=['Cod_setor', 'Cod_Grandes Regiï¿½es', 'Nome_Grande_Regiao', 'Cod_UF', 'Cod_meso', 
                              'Nome_da_meso', 'Cod_micro', 'Nome_da_micro', 'Cod_RM', 'Nome_da_RM', 'Cod_distrito', 
                              'Nome_do_distrito', 'Cod_subdistrito', 'Nome_do_subdistrito', 'Situacao_setor', 'Tipo_setor'])
ibge_col.head()

"""**AULA 04**"""

ibge_sp = pd.read_csv(ibge_url, sep=';',thousands='.', decimal=',', encoding='ISO-8859-1')
ibge.dropna(how='all', axis=1, inplace=True)
ibge_sp.head()

ibge_sp.info()

enderecos = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Imersão Alura/enderecos.csv")

enderecos.head()

enderecos_sp = enderecos.query("sigla_uf == 'SP'")
enderecos_sp

enderecos_sp["rua"] = enderecos_sp["tipo_logr"] + " " + enderecos_sp["logr_nome"]
enderecos_sp["rua"] = enderecos_sp["rua"].str.lower().str.strip()
enderecos_sp.head()

dados_vendas["Rua"].str.extract(r'(^[\w ]+)')[:10]

dados_vendas["apenas_rua"] = dados_vendas["Rua"].str.extract(r'(^[\w ]+)')
dados_vendas["apenas_rua"] = dados_vendas["apenas_rua"].str.lower().str.strip()
dados_vendas.head()

dados_geo = pd.merge(left = dados_vendas, right = enderecos_sp[["rua", "cep", "latitude", "longitude"]], how = "left", left_on = "apenas_rua", right_on = "rua").drop_duplicates(subset=dados_vendas.columns).query("cep > 0")
dados_geo

from shapely.geometry import Point
latitude = -23.98
longitude = -46.20
Point(longitude, latitude)

from shapely.geometry import Polygon
Polygon([[0,0], [1,0], [1,1], [0,1], [0,0]])

Polygon([[0,0], [1,0], [1,1], [0,1], [0,0]]).contains(Point(0.1,0.9))

!pip install geopandas

import geopandas as gpd

setor_censo = gpd.read_file('/content/drive/MyDrive/Colab Notebooks/Imersão Alura/setores censitarios/35SEE250GC_SIR.shp')
setor_censo.head()

setor_censo_sp = setor_censo[setor_censo.NM_MUNICIP == "SÃO PAULO"]
setor_censo_sp[setor_censo_sp.contains(Point(-46.63, -23.58))]

dados_geo["Point"] = ""
for i in dados_geo.index:
    dados_geo["Point"][i] = Point(dados_geo["longitude"][i], dados_geo["latitude"][i])

dados_geo['setor_censo'] = dados_geo["Point"].map(
    lambda x: setor_censo_sp.loc[setor_censo_sp.contains(x), 'CD_GEOCODI'].values
).str[0]
dados_geo.head()

dados_geo = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Imersão Alura/dados_geo.csv")
dados_geo.head()

dados_vendas_censo = pd.merge(left = dados_geo, right = ibge_sp, how = "left", left_on = "setor_censo", right_on = "Cod_setor")
dados_vendas_censo

dados_vendas_censo.info()

plt.figure(figsize=(10, 10))
sns.scatterplot(data = dados_vendas_censo, x="V005", y="Valor_m2");

"""**AULA 05**"""

dados_vendas_censo = dados_vendas_censo[['Rua', 'Bairro', 'Cidade', 'Metragem', 'Quartos', 'Banheiros', 'Vagas',
       'Valor_anuncio', 'Valor_mm', 'Valor_m2', 'latitude', 'longitude', 'Situacao_setor', 'V001',
       'V002', 'V003', 'V004', 'V005', 'V006', 'V007', 'V008', 'V009', 'V010',
       'V011', 'V012']].dropna()
dados_vendas_censo

plt.figure(figsize=(10, 8))
ax = sns.boxplot(data = dados_vendas_censo, y="Valor_anuncio")
plt.show()

dados_vendas_censo.query("Valor_anuncio > 30000000 | Valor_anuncio < 100000")

dados_vendas_censo.drop(dados_vendas_censo.query("Valor_anuncio > 30000000 | Valor_anuncio < 100000").index, inplace = True)
plt.figure(figsize=(10, 8))
ax = sns.boxplot(data = dados_vendas_censo, y="Valor_anuncio")
plt.show()

plt.figure(figsize=(10, 10))
sns.scatterplot(data = dados_vendas_censo, x="Valor_anuncio", y="Valor_m2")

dados_vendas_censo.corr()

import numpy as np
plt.figure(figsize=(18, 8))
mask = np.triu(np.ones_like(dados_vendas_censo.corr(), dtype=bool))
heatmap = sns.heatmap(dados_vendas_censo.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Correlação', fontdict={'fontsize':18}, pad=16);

"""**Regressão Linear**"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = dados_vendas_censo[["Metragem"]]
Y = dados_vendas_censo["Valor_anuncio"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 54)
lr = LinearRegression()

Y_train

lr.fit(X_train, Y_train)

Y_predict_test = lr.predict(X_test)

Y_test

Y_predict_train = lr.predict(X_train)

Y_train

from sklearn.metrics import mean_absolute_error, r2_score

mean_absolute_error(Y_test, Y_predict_test)

mean_absolute_error(Y_train, Y_predict_train)

"""**Regressão Multilinear**"""

X = dados_vendas_censo[['Metragem', 'Quartos', 'Banheiros', 'Vagas','V001','V007', 'V009']]
Y = dados_vendas_censo["Valor_anuncio"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 54)
lr.fit(X_train, Y_train)
Y_predict_test = lr.predict(X_test)
Y_predict_train = lr.predict(X_train)
mae_test = mean_absolute_error(Y_test, Y_predict_test)
r2_test = r2_score(Y_test, Y_predict_test)
mae_train = mean_absolute_error(Y_train, Y_predict_train)
r2_train = r2_score(Y_train, Y_predict_train)

mae_test

r2_test

mae_train

r2_train

plt.figure(figsize=(10, 10))
sns.scatterplot(x=Y_test, y=Y_predict_test)

